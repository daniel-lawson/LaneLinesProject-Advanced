{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subtle-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages ##\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mediterranean-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the camera calibration matrix and distortion coefficients given a set of chessboard images. ##\n",
    "\n",
    "def calibrate_camera(cal_img_folder):\n",
    "    #number of inside corners in x\n",
    "    nx = 9 \n",
    "    #number of inside corners in y\n",
    "    ny = 6 \n",
    "    #3D points in real world space\n",
    "    objpoints = []\n",
    "    #2D points in image plane\n",
    "    imgpoints =[] \n",
    "\n",
    "    #Prepare object points\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "    #Loop through calibration images\n",
    "    cal_files = os.listdir(cal_img_folder)\n",
    "    for file in cal_files:\n",
    "        #Import calibration images\n",
    "        cal_img = mpimg.imread(cal_img_folder + file) \n",
    "        #Convert to gray\n",
    "        gray_cal_img = cv2.cvtColor(cal_img, cv2.COLOR_BGR2GRAY) \n",
    "        #Find chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray_cal_img, (nx,ny), None) \n",
    "        #If corners are found, add object points and image points\n",
    "        if ret == True: \n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "\n",
    "    #Calulate matrix and distortion coefficients\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray_cal_img.shape[::-1], None, None)\n",
    "    \n",
    "    return ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "\n",
    "#Writeup/Test\n",
    "#ret, mtx, dist, rvecs, tvecs = calibrate_camera(\"camera_cal/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "marked-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply a distortion correction to raw images. ##\n",
    "\n",
    "def undistort_img(raw_img, mtx, dist):\n",
    "        #Unistort raw image\n",
    "        undistort_img = cv2.undistort(raw_img, mtx, dist, None, mtx)\n",
    "        #Fix coloring and save to folder\n",
    "        r,g,b = cv2.split(undistort_img)\n",
    "        undistorted_img = cv2.merge((b,g,r))\n",
    "        return undistorted_img\n",
    "        \n",
    "        \n",
    "#TEST\n",
    "#folder = \"test_images/\"\n",
    "#file = \"test2.jpg\"\n",
    "#raw_files = os.listdir(folder)\n",
    "#raw_img = mpimg.imread(folder + file)\n",
    "#undistorted_img = undistort_img(raw_img, mtx, dist)\n",
    "#gray_undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_RGB2GRAY)\n",
    "#plt.imshow(gray_undistorted_img, cmap = 'gray')\n",
    "\n",
    "#Writeup\n",
    "#raw_img = mpimg.imread(\"test_images/test4.jpg\")\n",
    "#undistorted_img = undistort_img(raw_img, mtx, dist)\n",
    "#cv2.imwrite(\"writeup_images/undistorted.jpg\", undistorted_img)\n",
    "#gray_undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "based-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use color transforms, gradients, etc., to create a thresholded binary image. ##\n",
    "\n",
    "#Absolute value of Sobel with inclusive threshold bounds\n",
    "def abs_sobel_thresh(gray_undistorted_img, orient, sobel_kernel, thresh):\n",
    "    #Determine orientation and find absolute value of sobel\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray_undistorted_img, cv2.CV_64F, 1, 0, sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray_undistorted_img, cv2.CV_64F, 0, 1, sobel_kernel))\n",
    "    #Scale to 8-bit\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    #Create binary mask where sobel thresholds are met\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    #Return mask\n",
    "    return binary_output\n",
    "\n",
    "#Magnitude of the gradient with inclusive threshold bounds\n",
    "def mag_thresh(gray_undistorted_img, sobel_kernel, thresh):\n",
    "    #Take gradient in x and y\n",
    "    sobelx = cv2.Sobel(gray_undistorted_img, cv2.CV_64F, 1, 0, sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray_undistorted_img, cv2.CV_64F, 0, 1, sobel_kernel)\n",
    "    #Calculate magnitude\n",
    "    sobel_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    #Scale to 8-bit (0-255) and convert to type = np.uint8\n",
    "    scale_factor = np.max(sobel_mag)/255\n",
    "    sobel_mag = (sobel_mag/scale_factor).astype(np.uint8)\n",
    "    #Create binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(sobel_mag)\n",
    "    binary_output[(sobel_mag >= thresh[0]) & (sobel_mag <= thresh[1])] = 1\n",
    "    #Return mask\n",
    "    return binary_output\n",
    "\n",
    "#Direction of the gradient with inclusive threshold bounds\n",
    "def dir_thresh(gray_undistorted_img, sobel_kernel, thresh):\n",
    "    #Take gradient in x and y\n",
    "    sobelx = cv2.Sobel(gray_undistorted_img, cv2.CV_64F, 1, 0, sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray_undistorted_img, cv2.CV_64F, 0, 1, sobel_kernel)\n",
    "    #Take absolute values\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    #Calculate direction\n",
    "    direction = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    #Create binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(direction)\n",
    "    binary_output[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    #Return mask\n",
    "    return binary_output\n",
    "     \n",
    "#HLS color threshold with inclusive lower and exlusive upper bounds\n",
    "def s_color_thresh(img, thresh):\n",
    "    #Convert to HLS and seprate S filter\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    S = hls[:,:,2]\n",
    "    #Create binary mask where color thresholds are met\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "#Stack all thresholds\n",
    "def stack_thresholds(undistorted_gray_img, undistorted_img, ksize):\n",
    "    gradx = abs_sobel_thresh(undistorted_gray_img, 'x', ksize, (30, 60))\n",
    "    grady = abs_sobel_thresh(undistorted_gray_img, 'y', ksize, (30, 60))\n",
    "    mag_binary = mag_thresh(undistorted_gray_img, ksize, (90, 180))\n",
    "    dir_binary = dir_thresh(undistorted_gray_img, ksize, (0.7, 1.3))\n",
    "    color_channel = s_color_thresh(undistorted_img, (90, 255))\n",
    "    stack_all = np.zeros_like(dir_binary)\n",
    "    stack_all[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1)) | (color_channel ==1)] = 1\n",
    "    return stack_all\n",
    "\n",
    "\n",
    "#TEST\n",
    "#gradx = abs_sobel_thresh(gray_undistorted_img, 'x', ksize, (30, 60))\n",
    "#grady = abs_sobel_thresh(gray_undistorted_img, 'y', ksize, (30, 60))\n",
    "#mag_binary = mag_thresh(gray_undistorted_img, ksize, (90, 150))\n",
    "#dir_binary = dir_thresh(gray_undistorted_img, ksize, (0.7, 1.3))\n",
    "#color_channel = s_color_thresh(undistorted_img, (90, 255))\n",
    "#thresh_img = stack_thresholds(gray_undistorted_img, undistorted_img, ksize)\n",
    "#f, (a1, a2, a3, a4, a5, a6) = plt.subplots(6, 1, figsize=(20,30))\n",
    "#a1.imshow(gradx, cmap='gray')\n",
    "#a1.set_title(\"sobel_x\")\n",
    "#a2.imshow(grady, cmap='gray')\n",
    "#a2.set_title(\"sobel_y\")\n",
    "#a3.imshow(mag_binary, cmap='gray')\n",
    "#a3.set_title(\"gradient magnitude\")\n",
    "#a4.imshow(dir_binary, cmap='gray')\n",
    "#a4.set_title(\"gradient direction\")\n",
    "#a5.imshow(color_channel, cmap='gray')\n",
    "#a5.set_title(\"S color channel\")\n",
    "#a6.imshow(thresh_img, cmap='gray')\n",
    "#a6.set_title(\"Everything\")\n",
    "\n",
    "#Writeup\n",
    "#thresh_img = stack_thresholds(gray_undistorted_img, undistorted_img, 9)\n",
    "#cv2.imwrite(\"writeup_images/binary.jpg\", thresh_img*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "plastic-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply a perspective transform to rectify binary image (\"birds-eye view\"). ##\n",
    "\n",
    "def perspective_transform(thresh_img):\n",
    "    #Points are hard-coded from image viewer window    \n",
    "    corners = np.float32([[250, 700], [585, 460], [700, 460], [1060, 700]])\n",
    "    #Offset from top right and top left\n",
    "    top_left = np.array([corners[0, 0], 0])\n",
    "    top_right = np.array([corners[3, 0], 0])\n",
    "    offset = [50, 0]\n",
    "    #Get image size\n",
    "    img_size = (thresh_img.shape[1], thresh_img.shape[0])\n",
    "    #Define source points and destination points\n",
    "    src = np.float32([corners[0], corners[1], corners[2], corners[3]])\n",
    "    dst = np.float32([corners[0] + offset, top_left + offset, top_right - offset, corners[3] - offset])\n",
    "\n",
    "    #Transform\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    pers_trans = cv2.warpPerspective(thresh_img, M, img_size)\n",
    "    #Inverse matrix to use later\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    return pers_trans, Minv\n",
    "\n",
    "\n",
    "#TEST\n",
    "#pers_trans, Minv = perspective_transform(thresh_img)\n",
    "#plt.imshow(pers_trans, cmap='gray')\n",
    "\n",
    "#Writeup\n",
    "#pers_trans, Minv = perspective_transform(thresh_img)\n",
    "#cv2.imwrite(\"writeup_images/perspective_transform.jpg\", pers_trans*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aboriginal-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detect lane pixels and fit to find the lane boundary. ##\n",
    "\n",
    "def find_lane_pixels(perspective_transform):\n",
    "    #Create histogram of bottom half of image\n",
    "    histogram = np.sum(perspective_transform[perspective_transform.shape[0]//2:,:], axis=0)\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    #Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((perspective_transform, perspective_transform, perspective_transform))\n",
    "    #Starting x value of left line\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    #Starting x value of right line\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    #Number of sliding windows\n",
    "    nwindows = 9\n",
    "    #Width of windows +/- margin\n",
    "    margin = 100\n",
    "    #Minimum number of pixels to recenter window\n",
    "    minpix = 50\n",
    "    \n",
    "    #Find height of each windown\n",
    "    win_height = np.int(perspective_transform.shape[0]/nwindows)\n",
    "    #x and y positions of all nonzero pixels in the image\n",
    "    nonzero = perspective_transform.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    #Current x positions initially set to starting values\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    #Lists will receive lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    #Traverse each window\n",
    "    for window in range(nwindows):\n",
    "        #Identify window boundaries\n",
    "        win_y_low = perspective_transform.shape[0] - (window+1)*win_height\n",
    "        win_y_high = perspective_transform.shape[0] - window*win_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "    \n",
    "        #Identify the nonzero pixels in x and y within the window \n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        #Add these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        #If > minpix pixels are found, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "            \n",
    "    #Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        #Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "    \n",
    "    #Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(perspective_transform, leftx, lefty, rightx, righty):\n",
    "    #Fit polynomials to each line\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    #Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, perspective_transform.shape[0]-1, perspective_transform.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]    \n",
    "\n",
    "    return ploty, left_fitx, right_fitx\n",
    "\n",
    "\n",
    "#TEST\n",
    "#leftx, lefty, rightx, righty, out_img = find_lane_pixels(pers_trans)\n",
    "#ploty, left_fitx, right_fitx = fit_polynomial(out_img, leftx, lefty, rightx, righty)\n",
    "#plt.imshow(poly_lines)\n",
    "#plt.plot(left_fitx, ploty, color='red')\n",
    "#plt.plot(right_fitx, ploty, color='red')\n",
    "\n",
    "#Writeup\n",
    "#leftx, lefty, rightx, righty, poly_lines = find_lane_pixels(pers_trans)\n",
    "#ploty, left_fitx, right_fitx = fit_polynomial(poly_lines, leftx, lefty, rightx, righty)\n",
    "#plt.imshow(poly_lines)\n",
    "#plt.plot(left_fitx, ploty, color='red')\n",
    "#plt.plot(right_fitx, ploty, color='red')\n",
    "#plt.savefig(\"writeup_images/poly_lines.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bacterial-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine the curvature of the lane and vehicle position with respect to center. ##\n",
    "\n",
    "def measure_curvature(ploty, left_fitx, right_fitx):\n",
    "    #Max y value used to determine radius of curvature\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    #Find polynomials in meters\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    \n",
    "    #Calculate radius of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad, left_fit_cr, right_fit_cr\n",
    "\n",
    "\n",
    "def measure_distance_from_center(poly_lines, left_fit_cr, right_fit_cr):\n",
    "    #image height and width\n",
    "    height = poly_lines.shape[0] * ym_per_pix\n",
    "    width = poly_lines.shape[1] * xm_per_pix\n",
    "    \n",
    "    #Finding x intercepts in meters\n",
    "    left_int = left_fit_cr[0]*height**2 + left_fit_cr[1]*height + left_fit_cr[2]\n",
    "    right_int = right_fit_cr[0]*height**2 + right_fit_cr[1]*height + right_fit_cr[2]\n",
    "    #Find lane center\n",
    "    lane_center = (left_int + right_int) / 2.0\n",
    "    \n",
    "    #calculate center of car\n",
    "    car_center = width / 2.0\n",
    "    \n",
    "    #calculate distance from center of car to center of lane\n",
    "    car_deviation = car_center - lane_center\n",
    "    return car_deviation\n",
    "\n",
    "\n",
    "#TEST\n",
    "#ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "#xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "#left_curverad, right_curverad, left_fit_cr, right_fit_cr = measure_curvature(ploty, left_fitx, right_fitx)\n",
    "#print(left_curverad, right_curverad, left_fit_cr, right_fit_cr)\n",
    "#car_deviation = measure_distance_from_center(poly_lines, left_fit_cr, right_fit_cr)\n",
    "#print(car_deviation)\n",
    "\n",
    "#Writeup\n",
    "#ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "#xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "#left_curverad, right_curverad, left_fit_cr, right_fit_cr = measure_curvature(ploty, left_fitx, right_fitx)\n",
    "#car_deviation = measure_distance_from_center(poly_lines, left_fit_cr, right_fit_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "increasing-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Warp the detected lane boundaries back onto the original image. ##\n",
    "\n",
    "def draw_on_orig(pers_trans, raw_img, left_fitx, right_fitx, ploty, left_curverad, right_curverad, car_deviation, Minv):\n",
    "    #Create an image to draw the lines on\n",
    "    img_zero = np.zeros_like(pers_trans).astype(np.uint8)\n",
    "    img_with_drawing = np.dstack((img_zero, img_zero, img_zero))\n",
    "\n",
    "    #Input x and y points into cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    #Draw the lines onto warped blank image\n",
    "    cv2.fillPoly(img_with_drawing, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    #Use inverse matrix to unwarp image\n",
    "    unwarp = cv2.warpPerspective(img_with_drawing, Minv, (raw_img.shape[1], raw_img.shape[0])) \n",
    "    #Add to original image\n",
    "    final_result = cv2.addWeighted(raw_img, 1, unwarp, 0.3, 0)\n",
    "    \n",
    "    #Write text\n",
    "    curv_rad_text = \"Radius of Curvature = \" + str(np.round((left_curverad+right_curverad)/2)) + \"m\"\n",
    "    car_deviation = round(car_deviation, 2)\n",
    "    #Determine if car is left of or right of center\n",
    "    if car_deviation < 0:\n",
    "        car_deviation = (abs(car_deviation)).astype(str)\n",
    "        car_deviation_text = \"Vehicle is \" + car_deviation + \"m left of center\"\n",
    "    elif car_deviation > 0:\n",
    "        car_deviation = (abs(car_deviation)).astype(str)\n",
    "        car_deviation_text = \"Vehicle is \" + car_deviation + \"m right of center\"\n",
    "    else:\n",
    "        car_deviation_text = \"Vehicle is centered\"\n",
    "    \n",
    "    cv2.putText(final_result, curv_rad_text, (25,75), cv2.FONT_HERSHEY_DUPLEX , 2, (255,255,255), 2)\n",
    "    cv2.putText(final_result, car_deviation_text, (25,150), cv2.FONT_HERSHEY_DUPLEX , 2, (255,255,255), 2)\n",
    "    \n",
    "    return final_result\n",
    "    \n",
    "    \n",
    "#TEST\n",
    "#result = draw_on_orig(pers_trans, raw_img, left_fitx, right_fitx, ploty, left_curverad, right_curverad, car_deviation, Minv)\n",
    "#plt.imshow(result)\n",
    "\n",
    "#Writeup\n",
    "#result = draw_on_orig(pers_trans, raw_img, left_fitx, right_fitx, ploty, left_curverad, right_curverad, car_deviation, Minv)\n",
    "#r,g,b = cv2.split(result)\n",
    "#result = cv2.merge((b,g,r))\n",
    "#cv2.imwrite(\"writeup_images/result.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tamil-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine everything. ##\n",
    "\n",
    "def process_image(raw_img):\n",
    "    #Undistort image\n",
    "    undistorted_img = undistort_img(raw_img, mtx, dist)\n",
    "    #Convert image to gray\n",
    "    gray_undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_RGB2GRAY)\n",
    "    #Apply thresholds to image\n",
    "    thresh_img = stack_thresholds(gray_undistorted_img, undistorted_img, ksize)\n",
    "    #Perfom perspective transform on image\n",
    "    pers_trans, Minv = perspective_transform(thresh_img)\n",
    "    #Find lane pixels\n",
    "    leftx, lefty, rightx, righty, poly_lines = find_lane_pixels(pers_trans)\n",
    "    #Fit polynomial to lanes\n",
    "    ploty, left_fitx, right_fitx = fit_polynomial(poly_lines, leftx, lefty, rightx, righty)\n",
    "    #Measure curvature of lanes\n",
    "    left_curverad, right_curverad, left_fit_cr, right_fit_cr = measure_curvature(ploty, left_fitx, right_fitx)\n",
    "    #Measure car deviation from center of lane\n",
    "    car_deviation = measure_distance_from_center(poly_lines, left_fit_cr, right_fit_cr)\n",
    "    #Add graphics and text to original image\n",
    "    result = draw_on_orig(pers_trans, raw_img, left_fitx, right_fitx, ploty, left_curverad, right_curverad, car_deviation, Minv)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "liable-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate test images. ##\n",
    "\n",
    "#Calibrate Camera\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate_camera(\"camera_cal/\")\n",
    "\n",
    "#Setting kernel size\n",
    "ksize = 9\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "#Set input and output folders\n",
    "input_folder = \"test_images/\"\n",
    "output_folder = \"output_images/\"\n",
    "raw_files = os.listdir(input_folder)\n",
    "\n",
    "#Loop through input folder and save to output folder\n",
    "for file in raw_files:\n",
    "    raw_img = mpimg.imread(input_folder + file)\n",
    "    result = process_image(raw_img)\n",
    "    r,g,b = cv2.split(result)\n",
    "    result = cv2.merge((b,g,r))\n",
    "    cv2.imwrite(output_folder + file + \".jpg\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "superior-shirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|                                                                            | 0/1260 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video.mp4.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n",
      "Wall time: 5min 38s\n"
     ]
    }
   ],
   "source": [
    "## Run pipeline on video. ##\n",
    "\n",
    "#Calibrate Camera\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate_camera(\"camera_cal/\")\n",
    "\n",
    "#Setting kernel size\n",
    "ksize = 9\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "video_output = \"output_video.mp4\"\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")#.subclip(0,5)\n",
    "clip1_output = clip1.fl_image(process_image)\n",
    "%time clip1_output.write_videofile(video_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ongoing-gilbert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
